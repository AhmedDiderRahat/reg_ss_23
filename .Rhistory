# took  the probability of attitude and education
(tabAErel <- prop.table(tabAE, margin = 2))
# Plot attitude and education
plot(t(tabAE), main="Attitude towards corporl punishment by education",
las=1, cex.axis=0.85)
barplot(tabAErel, beside = TRUE,ylim = c(0,1),
main = "Attitudes towards corporal punishment", las=1)
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
# Second plot
par(mfrow=c(2,1))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.6), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.7), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.70), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.90), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.80), xpd=NA))
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x= "bottom", ncol=2, bty="n", inset=c(0,-0.70), xpd=NA))
barplot(tabAErel, beside = TRUE, ylim = c(0,1),
main = "Attitudes towards corporal punishment", las=1)
barplot(tabAErel, ylim = c(0,1),
main="Attitudes towards corporal punishment",
las = 1, legend=TRUE,
args.legend = list(x="bottom", ncol=2, bty="n", inset=c(0,-0.70), xpd=NA))
# Inspect table object
str(tabAE)
str(tabAErel)
attributes(tabAE)
attributes(tabAErel)
?indentical
?identical
identical(attributes(tabAE), attributes(tabAErel))
identical(attributes(tabAE), attributes(tabAErel)[c(1,4,2: 3)])
identical(attributes(tabAE), attributes(tabAErel)[c(1,4,2,3)])
a
a <- 3
a
X <- rnorm(1000, -3, 0.25)
X
X <- rnorm(1000, -3, 0.25)
p_x <- pnorm(-2.5, mean=-3, sd=0.25, lower.tail=FALSE)
p_x
p_x <- pnorm(-2.5, mean=-3, sd=0.25, lower.tail=TRUE)
p_x
?pnorm
?pnorm
s_x <- qnorm(-2.5, mean=-3, sd=0.25, lower.tail=FALSE, log.p=FALSE)
s_x
g_x <- qnorm(-2.5, mean=-3, sd=0.25, lower.tail=TRUE, log.p=FALSE)
g_x
s_x <- qnorm(-2.5, mean=-3, sd=0.25, lower.tail=FALSE, log.p=FALSE)
s_x
p_x <- pnorm(-2.5, mean=-3, sd=0.25, lower.tail=TRUE)
p_x
g_x <- pnorm(-2.5, mean=-3, sd=0.25, lower.tail=TRUE)
g_x
s_x <- pnorm(-2.5, mean=-3, sd=0.25, lower.tail=FALSE)
s_x
g_x+s_x
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
install.packages('knitr', dependencies = TRUE)
set.seed(2)
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
x[1:25,1]<-x[1:25,1]+2
x[1:25,2]<-x[1:25,2]-2
plot(x,pch=16)
print(x)
km.out<-kmeans(x,centers=2,nstart=1) #run with two clusters
km.out$cluster #a vector specifying which cluster each row belongs to
names(km.out) #all the different outputs from kmeans
km.out$totss #the sum of squares without clustering
km.out$tot.withinss #the sum of squares with this clustering
km.out$withinss #the sum of squares within each cluster
km.out$centers #Matrix with the center coordinates
plot(x,col=km.out$cluster+1,pch=16) #plot the poiunts colorfed by cluster
points(km.out$centers,col=2:3,pch=3) #add the cluster centers
km.out<-kmeans(x,centers=2,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
points(km.out$centers,col=2:3,pch=3)
km.out$tot.withinss
set.seed(4)
km.out<-kmeans(x,centers=3,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
km.out<-kmeans(x,centers=4,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
km.out$tot.withinss
x<-matrix(rnorm(50*3),ncol=2)
x[1:25,1]<-x[1:25,1]+2
x[1:25,1]<-x[1:25,1]+2
x[1:25,2]<-x[1:25,2]-2
x[50+1:25,1]<-x[50+1:25,1]+2
x[50+1:25,2]<-x[50+1:25,2]+2
km.out<-kmeans(x,3,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
points(km.out$centers,col=2:4,pch=3)
km.out$tot.withinss
set.seed(4)
km.out<-kmeans(x,centers=3,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
km.out<-kmeans(x,centers=4,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
km.out$tot.withinss
x<-matrix(rnorm(50*3),ncol=2)
x[1:25,1]<-x[1:25,1]+2
x[1:25,2]<-x[1:25,2]-2
x[50+1:25,1]<-x[50+1:25,1]+2
x[50+1:25,2]<-x[50+1:25,2]+2
km.out<-kmeans(x,3,nstart=20)
plot(x,col=km.out$cluster+1,pch=16)
points(km.out$centers,col=2:4,pch=3)
km.out$tot.withinss
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(dplyr)
library(dplyr)
library(mdsr)
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
install.packages("Rcpp")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(Rcpp)
library(dplyr)
library(mdsr)
install.packages("mdsr")
install.packages("mdsr")
install.packages("mdsr")
q()
R.version.string
cls
x <- c(0.5, 0.6)
print(typeof(x))
x <- c(0.5, 6)
print(typeof(x))
x <- c(0.5, 0.6)
print(typeof(x))
x <- c(TRUE, FALSE)
print(typeof(x))
x <- c(T, F)
print(typeof(x))
x <- c("a", "b", "c")
print(typeof(x))
x <- 9:29
print(typeof(x))
x <- c(1+0i, 2+4i)
print(typeof(x))
x <- c(1.7, "a")
print(typeof(x))
x <- c(1.7, "a", 6L)
print(typeof(x))
x <- c(TRUE, 2)
print(typeof(x))
x <- c("a", TRUE, 1)
print(typeof(x))
x <- c("a", c(TRUE, 1))
print(typeof(x))
x <- c(1+2i, c(TRUE, 1))
print(typeof(x))
"a"
x <- c("a", c(TRUE, 1))
print(typeof(x))
print(class(x))
# Explicit Coercion
x <- 0:6
class(x)
x <- as.numeric(x)
class(x)
# Explicit Coercion
x <- 0:6
class(x) # integer
y <- as.numeric(x)
class(y)
y <- as.logical(x)
class(y)
y <- as.character(x)
class(y)
y <- as.character(x)
class(y)
y
y <- as.complex(x)
class(y)
# Nonsensical coercion results in NAs.
x <- c("a", "b", "c")
class(x)
y <- as.logical(x)
class(y)
# Nonsensical coercion results in NAs.
x <- c("a", "b", "c")
y <- as.numeric(x)
class(y)
print(y)
x <- factor(c("yes", "yes", "no", "yes", "no"))
x
table(x)
unclass(x)
# levels could be set by using lavels arguments
x <- factor(c("yes", "yes", "no", "yes", "no"), levels = c("yes", "no"))
x
table(x)
unclass(x)
# Reorder and Levels of a factor
x
relevel(x, ref="no")
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels = c(TRUE, FALSE),
levels = c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels = c(TRUE, FALSE),
levels = c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam, levels = c(TRUE, FALSE), levels = c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels=c("success", "failure"))
exam <- factor(exam,
levels = c(TRUE, FALSE),
levels = c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels = c(TRUE, FALSE),
levels = c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels=c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels=c("success", "failure"))
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
levels=c("success", "failure"))
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels = c("success", "failure"))
print(exam)
table(exam)
## New and relabeled Levels
exam <- c(TRUE, TRUE, FALSE, TRUE, FALSE)
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels = c("success", "failure"))\
exam <- factor(exam,
levels=c(TRUE, FALSE),
labels = c("success", "failure"))
print(exam)
table(exam)
x <- data.frame(eggs = 1:4, ham = c(TRUE, TRUE, FALSE, FALSE))
print(x)
print(nrow(x))
print(ncol(x)) # number of column
print(dim(x)) # total dimension
x <- data.frame(my_num = 1:4,
my_char = "a",
my_logic = c(TRUE, FALSE, FALSE, TRUE))
print(x)
str(x)
x <- list(1, "a", TRUE)
print(typeof(x))
print(x)
x <- list(1, 2, "a", TRUE)
print(typeof(x))
print(x)
x <- list(a = 1,
b = list(1, 2),
c = data.frame(x = 1:2))
print(x)
str(x)
x <- 5:15
x
# Preparations
rm(list = ls(all.names = TRUE))
x <- 5:15
x
quantile(x, probs = 0.5)
quantile(x, probs = 0.1)
quantile(x, probs = c(0.1, 0.11))
0.11*11
quantile(x)
# Deciles
quantile(x, probs = 1:9/10)
# Percentiles
quantile(x, prob = 1:99/100)
# BMI
bmi <- c(18.13, 18.53, 20.75, 21.86, 22.65, 22.93, 22.95, 23.75, 23.82, 24.01, 24.68, 24.89, 25.25,
25.75, 25.85, 25.9, 26.11, 26.73, 27.2, 27.67, 27.94, 28.19, 29.29, 31.22, 32.37)
boxplot(bmi)
library(AER)
# Preparations
rm(list = ls(all.names = TRUE))
library(AER)
data(CPS1985)
## get help with ?CPS1985
str(CPS1985)
attach(CPS1985)  ## load variables into workspace
## t.tests from Statistical Computing
#########################################################
## example of a hypothesis: is wage dependent on gender?
## compare the two groups w.r.t. wage
boxplot(wage~gender)
t.test(wage~gender)  ## H0 (means are equal) rejected
## example of a hypothesis: is expected wage around 9 US Dollar?
mean(wage)
t.test(wage,mu=9)    ## H0 (mean is 9) not rejected
lm1 <- lm(log(wage) ~ education + experience + I(experience^2) )
summary(lm1)  ## all coefficients are significantly different from 0 again
lm2 <- lm(log(wage) ~ education + I(education^2) + experience + I(experience^2) )
summary(lm2)  ## education is not significantly different from 0 (at 5%)
lm3 <- lm(log(wage) ~ I(education^2) + experience + I(experience^2) )
summary(lm3)  ## all coefficients are significantly different from 0 again
## a chi^2 distribution arises from a sum of squared N(0,1) variables
df <- 20
nsim <- 50000
z <- matrix(rnorm(nsim*df), nsim, df)
z
y <- rowSums(z^2); length(y)  ## y is then chi^2 distributed
plot(fh <- density(y))
## approximate expectation by mean (expection=df)
mean(y)
var(y)  ## variance=2*df
## theoretical chi^2 distribution
lines(fh$x, dchisq(fh$x,df=df), col="blue")
## t distrbution
df <- 4  ## the larger df, the closer to dnorm
## a chi^2 distribution arises from a sum of squared N(0,1) variables
df <- 25
nsim <- 50000
z <- matrix(rnorm(nsim*df), nsim, df)
y <- rowSums(z^2); length(y)  ## y is then chi^2 distributed
plot(fh <- density(y))
## approximate expectation by mean (expection=df)
mean(y)
var(y)  ## variance=2*df
## theoretical chi^2 distribution
lines(fh$x, dchisq(fh$x,df=df), col="blue")
## a chi^2 distribution arises from a sum of squared N(0,1) variables
df <- 20
nsim <- 50000
z <- matrix(rnorm(nsim*df), nsim, df)
y <- rowSums(z^2); length(y)  ## y is then chi^2 distributed
plot(fh <- density(y))
## approximate expectation by mean (expection=df)
mean(y)
var(y)  ## variance=2*df
## theoretical chi^2 distribution
lines(fh$x, dchisq(fh$x,df=df), col="blue")
## t distrbution
df <- 4  ## the larger df, the closer to dnorm
grid <- seq(-5,5,by=0.1)
plot(grid, dt(grid,df=df), type="l", col="blue") ## has more fat tail than dnorm
lines(grid,dnorm(grid))
## approximate expectation by mean (expectation=0)
nsim <- 1000
t <- rt(nsim, df=df)
mean(t)
set.seed(5721)  ## fix the seed to always have the same data
x <- runif(10)
y <- 2 - 2*x + 0.5*x^2 + rnorm(length(x), sd=0.2)
lm1 <- lm( y ~ x )
lm2 <- lm( y ~ x + I(x^2))
lm3 <- lm( y ~ x + I(x^2) + I(x^3) )
X1 <- model.matrix(lm1)
X2 <- model.matrix(lm2)
X3 <- model.matrix(lm3)
P1 <- X1 %*% solve( t(X1) %*% X1 ) %*% t(X1)
P2 <- X2 %*% solve( t(X2) %*% X2 ) %*% t(X2)
P3 <- X3 %*% solve( t(X3) %*% X3 ) %*% t(X3)
trace <- function(P){ sum(diag(P)) }
trace(P1)
trace(P2)
trace(P3)
P2 %*% P1 - P1
max(abs( P2 %*% P1 - P1 ))
max(abs( P3 %*% P1 - P1 ))
max(abs( P3 %*% P2 - P2 ))
Anscombe <- read.csv("AnscombeQuartet.csv")
getwd()
setwd('C:\\Users\\DELL\\Desktop\\Summer 2023\\RegDS23\\reg_ss_23')
Anscombe <- read.csv("Dataset/AnscombeQuartet.csv")
lm1 <- lm(y1 ~ x1, data=Anscombe); summary(lm1)$r.squared
lm2 <- lm(y2 ~ x2, data=Anscombe); summary(lm2)$r.squared
lm3 <- lm(y3 ~ x3, data=Anscombe); summary(lm3)$r.squared
lm4 <- lm(y4 ~ x4, data=Anscombe); summary(lm4)$r.squared  ## all R^2 similar
par(mfrow=c(2,2))
plot(Anscombe$x1,Anscombe$y1, pch="+"); abline(lm1,col="red")
plot(Anscombe$x2,Anscombe$y2, pch="+"); abline(lm2,col="red")
plot(Anscombe$x3,Anscombe$y3, pch="+"); abline(lm3,col="red")
plot(Anscombe$x4,Anscombe$y4, pch="+"); abline(lm4,col="red")
par(mfrow=c(1,1))
View(Anscombe)
head(Anscombe)
regmodel <- function(x, y) {
lobj <- lm(Y ~ X)
print(summary(lobj)$r.squared)
plot(X, Y, pch="+")
abline(lobj, col="red")
}
regmodel(Anscombe$x1, Anscombe$y1)
regmodel <- function(X, Y) {
lobj <- lm(Y ~ X)
print(summary(lobj)$r.squared)
plot(X, Y, pch="+")
abline(lobj, col="red")
}
regmodel(Anscombe$x1, Anscombe$y1)
data <- read.csv("Dataset/AnscombeQuartet.csv")
regmodel(data$x1, data$y1)
par(mfrow=c(2,2))
regmodel <- function(X, Y) {
lobj <- lm(Y ~ X)
print(summary(lobj)$r.squared)
plot(X, Y, pch="+")
abline(lobj, col="red")
}
regmodel(data$x1, data$y1)
regmodel(data$x2, data$y2)
regmodel(data$x3, data$y3)
regmodel(data$x4, data$y4)
